{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamyse1/GenAI/blob/main/Week3/Ex2.Building_a_Simplified_Transformer_Encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 3 Hands-on Lab: Building a Simplified Transformer Encoder**"
      ],
      "metadata": {
        "id": "UvODY4XYGS4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This hands-on lab allows you to understand the Transformer architecture by implementing a basic Transformer encoder. You will learn how input embeddings, positional encodings, and feedforward layers work together in an encoder block. We will be using the Torch framework to build a simple transformer encoder."
      ],
      "metadata": {
        "id": "tV7jIspzGcIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: Input Embedding and Positional Encoding**"
      ],
      "metadata": {
        "id": "UD0bA42xGnZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.\tGenerate Input Data**\n",
        "Define a sample sentence and tokenize it into a numerical format.\n"
      ],
      "metadata": {
        "id": "B-uZW8_bGvUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Example sentence and token IDs (simplified for illustration)\n",
        "token_ids = torch.tensor([[1, 2, 3, 4, 5]])  # Tokenized sentence\n",
        "vocab_size = 10  # Vocabulary size\n",
        "embedding_dim = 8  # Embedding size"
      ],
      "metadata": {
        "id": "bulopUQ1GzrC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Create an Embedding Layer**\n",
        "Implement the embedding layer to convert token IDs into dense vectors."
      ],
      "metadata": {
        "id": "4khCooiqIdHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
        "embedded_tokens = embedding_layer(token_ids)\n",
        "print(\"Embedded Tokens:\\n\", embedded_tokens)"
      ],
      "metadata": {
        "id": "LjWIeI7GIoEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "807a7e62-2d0c-491a-aed8-b3a22588c95c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedded Tokens:\n",
            " tensor([[[ 0.2448, -0.2579,  0.2403,  1.4379, -0.1118,  0.1126,  0.3993,\n",
            "          -0.4770],\n",
            "         [-0.6451,  0.4526,  2.6516,  0.1126, -1.6482,  1.1013,  0.5487,\n",
            "          -0.5053],\n",
            "         [ 0.1692, -0.3968, -0.1419,  0.4164, -1.2760, -1.0351, -0.6201,\n",
            "          -1.0014],\n",
            "         [ 0.6725,  1.1687,  0.4561, -1.9743, -0.7707, -0.1076, -1.9188,\n",
            "           0.2917],\n",
            "         [ 0.2650, -0.5033,  0.2574,  0.4430,  1.8879, -0.7403,  2.0639,\n",
            "           0.1423]]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.\tAdd Positional Encoding**\n",
        "Incorporate positional encoding to provide positional information to the model.\n"
      ],
      "metadata": {
        "id": "EfdPOMcpG_qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(seq_len, embedding_dim):\n",
        "    position = np.arange(seq_len)[:, np.newaxis]\n",
        "    div_term = np.exp(np.arange(0, embedding_dim, 2) * -(np.log(10000.0) / embedding_dim))\n",
        "    pe = np.zeros((seq_len, embedding_dim))\n",
        "    pe[:, 0::2] = np.sin(position * div_term)\n",
        "    pe[:, 1::2] = np.cos(position * div_term)\n",
        "    return torch.tensor(pe, dtype=torch.float)\n",
        "\n",
        "seq_len = token_ids.size(1)\n",
        "pos_encoding = positional_encoding(seq_len, embedding_dim)\n",
        "print(\"Positional Encoding:\\n\", pos_encoding)\n"
      ],
      "metadata": {
        "id": "Mti1h0tXHDXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a810e38-5ee1-48b0-9f43-986c76b7b8f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positional Encoding:\n",
            " tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "        [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
            "          9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
            "        [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
            "          9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
            "        [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9996e-02,\n",
            "          9.9955e-01,  3.0000e-03,  1.0000e+00],\n",
            "        [-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n",
            "          9.9920e-01,  4.0000e-03,  9.9999e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the positional encoding to the embedded tokens:"
      ],
      "metadata": {
        "id": "iZm2hKp-HIxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_with_pos = embedded_tokens + pos_encoding.unsqueeze(0)\n",
        "print(\"Embedded Tokens with Positional Encoding:\\n\", embedded_with_pos)\n"
      ],
      "metadata": {
        "id": "TMwXiAIiHLm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d8369a-f2d4-4e03-c1c2-b069ec5c49d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedded Tokens with Positional Encoding:\n",
            " tensor([[[ 2.4482e-01,  7.4211e-01,  2.4028e-01,  2.4379e+00, -1.1180e-01,\n",
            "           1.1126e+00,  3.9929e-01,  5.2305e-01],\n",
            "         [ 1.9633e-01,  9.9293e-01,  2.7514e+00,  1.1076e+00, -1.6382e+00,\n",
            "           2.1013e+00,  5.4969e-01,  4.9468e-01],\n",
            "         [ 1.0785e+00, -8.1292e-01,  5.6792e-02,  1.3964e+00, -1.2560e+00,\n",
            "          -3.5344e-02, -6.1813e-01, -1.4076e-03],\n",
            "         [ 8.1359e-01,  1.7874e-01,  7.5164e-01, -1.0190e+00, -7.4069e-01,\n",
            "           8.9198e-01, -1.9158e+00,  1.2917e+00],\n",
            "         [-4.9184e-01, -1.1569e+00,  6.4680e-01,  1.3641e+00,  1.9279e+00,\n",
            "           2.5887e-01,  2.0679e+00,  1.1423e+00]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2: Add a Feedforward Layer**"
      ],
      "metadata": {
        "id": "wfM3VX60HQ6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\t**Define a Feedforward Neural Network**\n",
        "Implement a simple feedforward layer as part of the encoder.\n"
      ],
      "metadata": {
        "id": "oUaKhCEuHViQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedforward = nn.Sequential(\n",
        "    nn.Linear(embedding_dim, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, embedding_dim)\n",
        ")\n",
        "ff_output = feedforward(embedded_with_pos)\n",
        "print(\"Feedforward Output:\\n\", ff_output)\n"
      ],
      "metadata": {
        "id": "RIN1MxZVHZwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1094001-5aed-4e60-8e66-0248b06bf9ae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feedforward Output:\n",
            " tensor([[[ 0.1721,  0.3681,  0.3267, -0.1444,  0.0419, -0.5988,  0.3962,\n",
            "           0.2048],\n",
            "         [ 0.0111,  0.3325,  0.3242, -0.4747,  0.0032, -0.6876,  0.3106,\n",
            "           0.4848],\n",
            "         [ 0.0057,  0.1898,  0.3249, -0.2349,  0.0977, -0.5837,  0.2542,\n",
            "           0.2067],\n",
            "         [-0.0278, -0.0283,  0.0932,  0.0022, -0.0068, -0.3013,  0.1213,\n",
            "           0.1411],\n",
            "         [ 0.4647,  0.4109,  0.0456, -0.2412,  0.1968, -0.9455, -0.0137,\n",
            "           0.0439]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 3: Combine the Components into an Encoder Block**"
      ],
      "metadata": {
        "id": "xb9uak0OHcjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\t**Define the Encoder Block**\n",
        "Combine the embedding, positional encoding, and feedforward components into an encoder block.\n"
      ],
      "metadata": {
        "id": "qXVdYvwkHgdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, embedding_dim)\n",
        "        )\n",
        "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embedding(x)\n",
        "        pos_enc = positional_encoding(x.size(1), embed.size(2))\n",
        "        embed_with_pos = embed + pos_enc.unsqueeze(0)\n",
        "        ff_output = self.feedforward(embed_with_pos)\n",
        "        return self.layer_norm(embed_with_pos + ff_output)\n",
        "\n",
        "encoder = TransformerEncoderBlock(vocab_size, embedding_dim)\n",
        "output = encoder(token_ids)\n",
        "print(\"Encoder Output:\\n\", output)\n"
      ],
      "metadata": {
        "id": "70IMzzkPHmRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac7da2c9-4a82-47d4-f753-4987347d041a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Output:\n",
            " tensor([[[-1.0448, -0.5450,  0.9632,  1.7050,  0.0192,  0.0734, -1.6066,\n",
            "           0.4356],\n",
            "         [ 0.9758, -1.8320,  0.3634,  0.9183, -0.4838, -1.2596,  0.5426,\n",
            "           0.7754],\n",
            "         [ 2.4935, -0.1755, -0.5465, -0.1991, -1.1428, -0.0416, -0.3174,\n",
            "          -0.0705],\n",
            "         [-1.1091, -1.5216, -0.2775,  0.4408,  0.4907,  1.9340, -0.2957,\n",
            "           0.3384],\n",
            "         [ 0.5874, -1.0779, -0.9069,  1.1809, -1.3886, -0.0961,  0.1830,\n",
            "           1.5183]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4: Experiment with Different Inputs**\n",
        "\n",
        "* Test with Different Sentences\n",
        "Replace token_ids with new examples to observe how the encoder processes different inputs.\n",
        "* Modify Hyperparameters\n",
        "Experiment with different embedding sizes, feedforward dimensions, or positional encoding scales to see their effect on the output.\n"
      ],
      "metadata": {
        "id": "zfB-L5zlHqhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary**"
      ],
      "metadata": {
        "id": "IZW4m09oIIFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By completing this lab, you have:\n",
        "\n",
        "* Understood the role of embedding, positional encoding, and feedforward layers in the Transformer encoder.\n",
        "* Gained hands-on experience implementing a core component of the Transformer architecture.\n",
        "* Developed a deeper appreciation for the architecture’s design and functionality.\n",
        "\n",
        "This lab builds foundational knowledge of the Transformer, preparing you for more advanced concepts like self-attention.\n"
      ],
      "metadata": {
        "id": "49Ko4E9cH4df"
      }
    }
  ]
}